{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규칙\n",
    "- 각 이름은 띄어쓰기 없이 작성하기. 예를 들어, \"영업 시간\"이 아니라 \"영업시간\"으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user09/beaver/data/shared_files/dataset/dataset_menuoption_v1.xlsx\n",
      "/home/user09/beaver/data/shared_files/dataset/dataset_menuoption_v2_SQL_105200_preprocessed.xlsx\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    # store=\"프랭크버거\"\n",
    "    output_path = \"/home/user09/beaver/data/db\"\n",
    "    data_path = \"\"\n",
    "    save_path = \"\"\n",
    "    embedding_model= \"nlpai-lab/KoE5\" # \"BAAI/bge-m3\"\n",
    "    retriever_k=5\n",
    "    retriever_bert_weight=0.7\n",
    "    data_version='_menuoption_v1'\n",
    "    version='_menuoption_v2_SQL'\n",
    "    # info_type='STORE_INFO'   # STORE_INFO, TIME_INFO, MENU_INFO\n",
    "    store_num = 105200  # 103017(미스), 104049(홍콩), 104562(새마을), 104570(롤링), 105200(우아)\n",
    "    fill_nan = \"None\"  # 없는 정보의 경우에는 \"정보없음\"보다는 \"None\"이 나은 듯\n",
    "    # basic_info = [\"주차장\", \"씨씨티비\", \"영업시간\", \"예약가능여부\", \"전화번호\"]\n",
    "    seed=42 \n",
    "\n",
    "\n",
    "CFG.data_path = f\"/home/user09/beaver/data/shared_files/dataset/dataset{CFG.data_version}.xlsx\"\n",
    "print(CFG.data_path)\n",
    "CFG.save_path = f\"/home/user09/beaver/data/shared_files/dataset/dataset{CFG.version}_{CFG.store_num}_preprocessed.xlsx\"\n",
    "print(CFG.save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STORE_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우아하계 완정역점\n",
      "    STORE_NM           ROAD_NM  BSPLC_TELNO  T_CNT  P_CNT\n",
      "4  우아하계 완정역점  인천 서구 완정로10번길 16  01099923537     18     72\n",
      "Index(['STORE_NM', 'ROAD_NM', 'BSPLC_TELNO', 'T_CNT', 'P_CNT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "################ 전처리 ################\n",
    "from langchain.schema import Document\n",
    "\n",
    "# ['STORE_NO', 'STORE_NM', 'BRAND_NO', 'BRAND_NM', 'ROAD_NM', 'BSPLC_TELNO', 'X', 'Y', 'T_CNT', 'P_CNT']\n",
    "columns_to_use = ['STORE_NO', 'STORE_NM', 'ROAD_NM', 'BSPLC_TELNO', 'T_CNT', 'P_CNT']\n",
    "df_store = pd.read_excel(CFG.data_path, sheet_name='STORE_INFO', usecols=columns_to_use, dtype={\"BSPLC_TELNO\": str})\n",
    "\n",
    "df_store = df_store[df_store['STORE_NO']==CFG.store_num]  # 해당 매장 정보만 가져옴\n",
    "store = df_store['STORE_NM'].unique()[0]\n",
    "print(store)\n",
    "\n",
    "df_store.drop(columns=['STORE_NO'], inplace=True)\n",
    "\n",
    "df_store_col = df_store.columns\n",
    "\n",
    "# 결과 출력\n",
    "print(df_store)\n",
    "print(df_store_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         매장명                위치         전화번호  매장 내 테이블 개수  수용 가능 인원\n",
      "4  우아하계 완정역점  인천 서구 완정로10번길 16  01099923537           18        72\n"
     ]
    }
   ],
   "source": [
    "############## 컬럼명 변경 ##############\n",
    "# ['STORE_NO', 'STORE_NM', 'BRAND_NO', 'BRAND_NM', 'ROAD_NM', 'BSPLC_TELNO', 'X', 'Y', 'T_CNT', 'P_CNT']\n",
    "store_column_mapping = {\n",
    "    'STORE_NO': '상점번호',\n",
    "    'STORE_NM': '매장명',\n",
    "    'ROAD_NM': '위치',\n",
    "    'BSPLC_TELNO': '전화번호',\n",
    "    'X': '좌표 X',\n",
    "    'Y': '좌표 Y',\n",
    "    'T_CNT': '매장 내 테이블 개수',  # !!!!!!!!!!!!!!!!!\n",
    "    'P_CNT': '수용 가능 인원',\n",
    "}\n",
    "\n",
    "for col in df_store_col:\n",
    "    df_store = df_store.rename(columns={col: store_column_mapping[col]})\n",
    "    \n",
    "print(df_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 contents\n",
      "0        \"매장명\": 우아하계 완정역점\n",
      "1  \"위치\": 인천 서구 완정로10번길 16\n",
      "2     \"전화번호\": 01099923537\n",
      "3       \"매장 내 테이블 개수\": 18\n",
      "4          \"수용 가능 인원\": 72\n"
     ]
    }
   ],
   "source": [
    "############### 한 컬럼으로 통합 ###############\n",
    "def create_contents_rowwise(df):\n",
    "    contents_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            contents_data.append(f'\"{col}\": {row[col]}')\n",
    "    new_df = pd.DataFrame({'contents': contents_data})\n",
    "    return new_df\n",
    "\n",
    "# 함수 호출\n",
    "result_df_store = create_contents_rowwise(df_store)\n",
    "print(result_df_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATMNT_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PAYMNT_MN                                EASY_PAYMNT_TYPE_NM\n",
      "28      신용카드                                                NaN\n",
      "29        현금                                                NaN\n",
      "30    모바일상품권                                                NaN\n",
      "31       포인트                                                NaN\n",
      "32      매장쿠폰                                                NaN\n",
      "33       선불권                                                NaN\n",
      "34      간편결제  네이버페이, 비플제로페이, 삼성페이, 알리페이, 앱결제, 앱카드, 위챗페이, 카카오...\n",
      "Index(['PAYMNT_MN', 'EASY_PAYMNT_TYPE_NM'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일에서 필요한 컬럼만 가져오기\n",
    "columns_to_use = ['STORE_NO', 'PAYMNT_MN', 'EASY_PAYMNT_TYPE_NM']\n",
    "df_pay = pd.read_excel(CFG.data_path, sheet_name='PAYMNT_INFO', usecols=columns_to_use)\n",
    "\n",
    "# 매장 번호 필터링 (103017로 변경)\n",
    "df_pay = df_pay[df_pay['STORE_NO'] == CFG.store_num]  # 매장 번호에 맞는 데이터만 가져옴\n",
    "df_pay.drop(columns=['STORE_NO'], inplace=True)\n",
    "\n",
    "# EASY_PAYMNT_TYPE_NM의 첫 번째 값 처리 (결측값 확인 후 진행)\n",
    "# if not df_pay['EASY_PAYMNT_TYPE_NM'].dropna().empty:\n",
    "simple_pay = str(df_pay['EASY_PAYMNT_TYPE_NM'].dropna().iloc[0])  # 첫 번째 비어있지 않은 값 가져오기\n",
    "\n",
    "\n",
    "# PAYMNT_MN 컬럼을 문자열로 변환\n",
    "df_pay['PAYMNT_MN'] = df_pay['PAYMNT_MN'].astype(str)\n",
    "\n",
    "# 간편결제 문자열을 조건에 맞게 결합\n",
    "# if simple_pay:  # simple_pay가 None이 아닐 때만 수행\n",
    "#     df_pay.loc[df_pay['PAYMNT_MN'].str.strip() == '간편결제', 'PAYMNT_MN'] += \"(\" + simple_pay + \")\"\n",
    "# df_pay.drop(columns=['EASY_PAYMNT_TYPE_NM'], inplace=True)\n",
    "\n",
    "df_pay_col = df_pay.columns\n",
    "\n",
    "# 결과 출력\n",
    "print(df_pay)\n",
    "print(df_pay_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      결제수단                                             간편결제수단\n",
      "28    신용카드                                                NaN\n",
      "29      현금                                                NaN\n",
      "30  모바일상품권                                                NaN\n",
      "31     포인트                                                NaN\n",
      "32    매장쿠폰                                                NaN\n",
      "33     선불권                                                NaN\n",
      "34    간편결제  네이버페이, 비플제로페이, 삼성페이, 알리페이, 앱결제, 앱카드, 위챗페이, 카카오...\n"
     ]
    }
   ],
   "source": [
    "############## 컬럼명 변경 ##############\n",
    "# ['STORE_NO', 'PAYMNT_MN', 'EASY_PAYMNT_TYPE_NM']\n",
    "pay_column_mapping = {\n",
    "    'STORE_NO': '상점번호',\n",
    "    'PAYMNT_MN': '결제수단',\n",
    "    'EASY_PAYMNT_TYPE_NM': '간편결제수단',\n",
    "}\n",
    "\n",
    "for col in df_pay_col:\n",
    "    df_pay = df_pay.rename(columns={col: pay_column_mapping[col]})\n",
    "\n",
    "print(df_pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     결제수단  \\\n",
      "0  신용카드, 현금, 모바일상품권, 포인트, 매장쿠폰, 선불권, 간편결제   \n",
      "\n",
      "                                              간편결제수단  \n",
      "0  네이버페이, 비플제로페이, 삼성페이, 알리페이, 앱결제, 앱카드, 위챗페이, 카카오...  \n"
     ]
    }
   ],
   "source": [
    "# 간편결제 행 찾기\n",
    "easy_pay_row = df_pay[df_pay['결제수단'] == '간편결제']\n",
    "if not easy_pay_row.empty:\n",
    "    # 간편결제수단 값 추출\n",
    "    easy_pay_method = easy_pay_row['간편결제수단'].iloc[0]\n",
    "else:\n",
    "    easy_pay_method = np.nan\n",
    "    \n",
    "payment_methods = df_pay['결제수단'].tolist()\n",
    "payment_methods_str = \", \".join(payment_methods)\n",
    "\n",
    "df_pay = pd.DataFrame({\n",
    "    '결제수단': [payment_methods_str],\n",
    "    '간편결제수단': [easy_pay_method if pd.notna(easy_pay_method) else '없음']\n",
    "})\n",
    "\n",
    "print(df_pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            contents\n",
      "0     '결제수단': 신용카드, 현금, 모바일상품권, 포인트, 매장쿠폰, 선불권, 간편결제\n",
      "1  '간편결제수단': 네이버페이, 비플제로페이, 삼성페이, 알리페이, 앱결제, 앱카드,...\n"
     ]
    }
   ],
   "source": [
    "############### 한 컬럼으로 통합 ###############\n",
    "def create_contents_rowwise(df):\n",
    "    contents_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            contents_data.append(f\"'{col}': {row[col]}\")\n",
    "    new_df = pd.DataFrame({'contents': contents_data})\n",
    "    return new_df\n",
    "\n",
    "# 함수 호출\n",
    "result_df_pay = create_contents_rowwise(df_pay)\n",
    "print(result_df_pay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MENU_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    STD_CATEGORY_NM STD_PROD_NM INDI_TYPE_NM  PROD_BASE_PRICE OPTION_PROD_NM  \\\n",
      "498            메인메뉴   우아하계 한판세트           없음            55000            NaN   \n",
      "499            메인메뉴  숯불닭갈비갈비양념            없음            14000            NaN   \n",
      "500            메인메뉴  숯불닭갈비소금구이            없음            14000            NaN   \n",
      "\n",
      "     OPTION_PROD_PRICE  \n",
      "498                NaN  \n",
      "499                NaN  \n",
      "500                NaN  \n",
      "Index(['STD_CATEGORY_NM', 'STD_PROD_NM', 'INDI_TYPE_NM', 'PROD_BASE_PRICE',\n",
      "       'OPTION_PROD_NM', 'OPTION_PROD_PRICE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "################ 전처리 ################\n",
    "# ['STORE_NO', 'BRAND_NO', 'CATEGORY_NO', 'CATEGORY_NM', 'STD_CATEGORY_NM', 'PROD_NO', 'PROD_HIST_NO', 'PROD_NM', 'STD_PROD_NM', 'SET_PROD_YN', 'ORGIN_INDI', 'INDI_TYPE_NM', 'PROD_BASE_PRICE', 'QTY', 'OPTION_GROUP_NO', 'OPTION_GROUP_NM', 'MIN_SEL_CNT' ,'MAX_SEL_CNT', 'ESS_YN', 'OPTION_PROD_NO', 'OPTION_PROD_NM', 'OPTION_PROD_PRICE']\n",
    "columns_to_use = ['STORE_NO', 'STD_CATEGORY_NM', 'INDI_TYPE_NM', 'STD_PROD_NM', 'PROD_BASE_PRICE', 'OPTION_PROD_NM', 'OPTION_PROD_PRICE']\n",
    "df_menu = pd.read_excel(f'/home/user09/beaver/data/shared_files/dataset/dataset{CFG.data_version}.xlsx', sheet_name='MENU_INFO', usecols=columns_to_use)\n",
    "df_menu = df_menu[df_menu['STORE_NO']==CFG.store_num]\n",
    "df_menu.drop(columns=['STORE_NO'], inplace=True)\n",
    "df_menu['INDI_TYPE_NM'].fillna(\"없음\", inplace=True)\n",
    "\n",
    "df_menu_col = df_menu.columns\n",
    "\n",
    "print(df_menu[:3])\n",
    "print(df_menu_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     카테고리         메뉴명  특징     가격   옵션  추가가격\n",
      "498  메인메뉴   우아하계 한판세트  없음  55000  NaN   NaN\n",
      "499  메인메뉴  숯불닭갈비갈비양념   없음  14000  NaN   NaN\n",
      "500  메인메뉴  숯불닭갈비소금구이   없음  14000  NaN   NaN\n",
      "501  메인메뉴      닭목살구이   없음  13000  NaN   NaN\n",
      "502  메인메뉴    닭목살구이양념   없음  13000  NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "menu_column_mapping = {\n",
    "    'STORE_NO': '상점번호',\n",
    "    'STD_PROD_NM': '메뉴명',\n",
    "    'STD_CATEGORY_NM': '카테고리',\n",
    "    'INDI_TYPE_NM': '특징',\n",
    "    'PROD_BASE_PRICE': '가격',\n",
    "    'OPTION_PROD_NM': '옵션',\n",
    "    'OPTION_PROD_PRICE': '추가가격'\n",
    "}\n",
    "\n",
    "for col in df_menu_col:\n",
    "    df_menu = df_menu.rename(columns={col: menu_column_mapping[col]})\n",
    "    \n",
    "print(df_menu[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # 결과를 담을 딕셔너리 (메뉴명 기준으로 그룹화)\n",
    "# menu_group = {}\n",
    "\n",
    "# for _, row in df_menu.iterrows():\n",
    "#     # 특징 처리\n",
    "#     if row['특징'] == \"없음\":\n",
    "#         features = [row['카테고리']]\n",
    "#     else:\n",
    "#         # 특징과 카테고리를 콤마로 나눈 뒤 리스트로 합침\n",
    "#         features = row['특징'].split(\", \") + [row['카테고리']]\n",
    "\n",
    "#     menu_name = row['메뉴명']\n",
    "#     price = f\"{row['가격']}원\"\n",
    "\n",
    "#     # 동일한 메뉴가 이미 그룹화 딕셔너리에 있는지 확인\n",
    "#     if menu_name not in menu_group:\n",
    "#         menu_group[menu_name] = {\n",
    "#             \"메뉴명\": menu_name,\n",
    "#             \"가격\": price,\n",
    "#             \"특징\": features,\n",
    "#             \"옵션 및 추가금액\": {}\n",
    "#         }\n",
    "#     else:\n",
    "#         # 이미 있는 경우 특징을 추가적으로 합침 (중복 제거)\n",
    "#         menu_group[menu_name][\"특징\"] = list(set(menu_group[menu_name][\"특징\"] + features))\n",
    "\n",
    "#     # 추가가격 및 옵션 처리\n",
    "#     if not pd.isna(row['추가가격']):\n",
    "#         add_price = int(row['추가가격'])  # 정수로 변환\n",
    "#         option_price = f\"{add_price}원\"\n",
    "#         menu_group[menu_name][\"옵션 및 추가금액\"][row['옵션']] = option_price\n",
    "\n",
    "# # 결과 리스트 생성\n",
    "# result = []\n",
    "# for menu in menu_group.values():\n",
    "#     # 매칭되는 값에서 따옴표 제거\n",
    "#     menu_str = (\n",
    "#         '\"메뉴명\": ' + menu[\"메뉴명\"] + \", \"\n",
    "#         '\"가격\": ' + menu[\"가격\"] + \", \"\n",
    "#         '\"특징\": ' + str(menu[\"특징\"]) + \", \"\n",
    "#         '\"옵션 및 추가금액\": ' + str(menu[\"옵션 및 추가금액\"]).replace('\"', \"'\")\n",
    "#     )\n",
    "#     result.append(menu_str)\n",
    "\n",
    "# # 데이터프레임 생성\n",
    "# result_df_menu = pd.DataFrame({\"contents\": result})\n",
    "\n",
    "# # 출력\n",
    "# print(result_df_menu[:5])\n",
    "# print(result_df_menu['contents'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          contents\n",
      "0   \"메뉴명\": 우아하계 한판세트, \"가격\": 55000원, \"특징\": ['메인메뉴']\n",
      "1  \"메뉴명\": 숯불닭갈비갈비양념 , \"가격\": 14000원, \"특징\": ['메인메뉴']\n",
      "2  \"메뉴명\": 숯불닭갈비소금구이 , \"가격\": 14000원, \"특징\": ['메인메뉴']\n",
      "3      \"메뉴명\": 닭목살구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "4    \"메뉴명\": 닭목살구이양념 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "\"메뉴명\": 환타파인, \"가격\": 2000원, \"특징\": ['음료']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 결과를 담을 딕셔너리 (메뉴명 기준으로 그룹화)\n",
    "menu_group = {}\n",
    "\n",
    "for _, row in df_menu.iterrows():\n",
    "    # 특징 처리\n",
    "    if row['특징'] == \"없음\":\n",
    "        features = [row['카테고리']]\n",
    "    else:\n",
    "        # 특징과 카테고리를 콤마로 나눈 뒤 리스트로 합침\n",
    "        features = row['특징'].split(\", \") + [row['카테고리']]\n",
    "\n",
    "    menu_name = row['메뉴명']\n",
    "    price = f\"{row['가격']}원\"\n",
    "\n",
    "    # 동일한 메뉴가 이미 그룹화 딕셔너리에 있는지 확인\n",
    "    if menu_name not in menu_group:\n",
    "        menu_group[menu_name] = {\n",
    "            \"메뉴명\": menu_name,\n",
    "            \"가격\": price,\n",
    "            \"특징\": features,\n",
    "        }\n",
    "        # 옵션 및 추가금액 항목은 기본적으로 비활성화\n",
    "        if not pd.isna(row['옵션']):\n",
    "            menu_group[menu_name][\"옵션 및 추가금액\"] = {}\n",
    "\n",
    "    else:\n",
    "        # 이미 있는 경우 특징을 추가적으로 합침 (중복 제거)\n",
    "        menu_group[menu_name][\"특징\"] = list(set(menu_group[menu_name][\"특징\"] + features))\n",
    "\n",
    "    # 추가가격 및 옵션 처리\n",
    "    if not pd.isna(row['추가가격']) and not pd.isna(row['옵션']):\n",
    "        add_price = int(row['추가가격'])  # 정수로 변환\n",
    "        option_price = f\"{add_price}원\"\n",
    "        if \"옵션 및 추가금액\" not in menu_group[menu_name]:\n",
    "            menu_group[menu_name][\"옵션 및 추가금액\"] = {}\n",
    "        menu_group[menu_name][\"옵션 및 추가금액\"][row['옵션']] = option_price\n",
    "\n",
    "# 결과 리스트 생성\n",
    "result = []\n",
    "for menu in menu_group.values():\n",
    "    # 매칭되는 값에서 따옴표 제거\n",
    "    menu_str = (\n",
    "        '\"메뉴명\": ' + menu[\"메뉴명\"] + \", \"\n",
    "        '\"가격\": ' + menu[\"가격\"] + \", \"\n",
    "        '\"특징\": ' + str(menu[\"특징\"])\n",
    "    )\n",
    "    # 옵션 및 추가금액이 존재하는 경우에만 추가\n",
    "    if \"옵션 및 추가금액\" in menu:\n",
    "        menu_str += \", \" + '\"옵션 및 추가금액\": ' + str(menu[\"옵션 및 추가금액\"]).replace('\"', \"'\")\n",
    "    result.append(menu_str)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "result_df_menu = pd.DataFrame({\"contents\": result})\n",
    "\n",
    "# 출력\n",
    "print(result_df_menu[:5])\n",
    "print(result_df_menu['contents'][20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIME_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  WKDY SALE_BGN_TM SALE_END_TM STORE_REST_BGN_TM STORE_REST_END_TM\n",
      "0   매일         07시      23시59분                없음                없음\n"
     ]
    }
   ],
   "source": [
    "# 전처리\n",
    "columns_to_use = ['STORE_NO', 'WKDY', 'SALE_BGN_TM', 'SALE_END_TM', 'STORE_REST_BGN_TM', 'STORE_REST_END_TM']\n",
    "df_time = pd.read_excel(f'/home/user09/beaver/data/shared_files/dataset/dataset{CFG.data_version}.xlsx', sheet_name='TIME_INFO', usecols=columns_to_use)\n",
    "df_time = df_time[df_time['STORE_NO']==103017]\n",
    "\n",
    "# 1. 요일 매핑\n",
    "day_mapping = {\n",
    "    2: '월요일',\n",
    "    3: '화요일',\n",
    "    4: '수요일',\n",
    "    5: '목요일',\n",
    "    6: '금요일',\n",
    "    7: '토요일',\n",
    "    1: '일요일',\n",
    "    0: '매일'\n",
    "}\n",
    "df_time['WKDY'] = df_time['WKDY'].map(day_mapping)\n",
    "df_time.fillna(CFG.fill_nan, inplace=True)\n",
    "\n",
    "def convert_time_format(hhmmss):\n",
    "    if pd.isna(hhmmss) or hhmmss in [None, 'None']:\n",
    "        return \"없음\"\n",
    "    hhmmss = str(int(hhmmss)).zfill(6)\n",
    "    h = hhmmss[:2]\n",
    "    m = hhmmss[2:4]\n",
    "    if m == '00':\n",
    "        return h + '시'\n",
    "    else:\n",
    "        return h + '시' + m + '분'\n",
    "\n",
    "def handle_missing_values(df, columns):\n",
    "    for col in columns:\n",
    "        if df[col].isna().all():\n",
    "            # 해당 매장의 해당 컬럼의 모든 값이 없으면, 정보가 없는 것으로 간주하여 None값으로 채움\n",
    "            df[col] = CFG.fill_nan\n",
    "        else:\n",
    "            # 일부라도 값이 있으면 해당 요일에 브레이크 타임이 없는 경우 '없음'으로 채움\n",
    "            df[col] = df[col].fillna(\"없음\")\n",
    "    return df\n",
    "\n",
    "# 시간 변환 함수 적용\n",
    "df_time['SALE_BGN_TM'] = df_time['SALE_BGN_TM'].apply(convert_time_format)\n",
    "df_time['SALE_END_TM'] = df_time['SALE_END_TM'].apply(convert_time_format)\n",
    "df_time['STORE_REST_BGN_TM'] = df_time['STORE_REST_BGN_TM'].apply(convert_time_format)\n",
    "df_time['STORE_REST_END_TM'] = df_time['STORE_REST_END_TM'].apply(convert_time_format)\n",
    "\n",
    "# 빈값 처리 함수 적용\n",
    "columns_to_check = ['SALE_BGN_TM', 'SALE_END_TM', 'STORE_REST_BGN_TM', 'STORE_REST_END_TM']\n",
    "df_time = handle_missing_values(df_time, columns_to_check)\n",
    "\n",
    "# ===== 추가 로직 시작 =====\n",
    "# 모든 요일(일~토:1~7)의 정보가 존재하며, 모든 시간이 동일한 경우 '매일(0)'로 통합\n",
    "weekday_list = ['월요일','화요일','수요일','목요일','금요일','토요일','일요일']\n",
    "store_days = df_time['WKDY'].unique()\n",
    "\n",
    "# 요일이 모두 7개 다 존재하는지 확인 (요일 순서는 중요치 않으므로 집합으로 비교)\n",
    "if set(weekday_list).issubset(store_days):\n",
    "    # 모든 요일에 대해 시간 정보가 동일한지 확인\n",
    "    # 대표적으로 첫 번째 요일의 정보를 기준으로 비교\n",
    "    df_first_day = df_time[df_time['WKDY'] == weekday_list[0]].iloc[0]\n",
    "    same_time = True\n",
    "    for w in weekday_list[1:]:\n",
    "        df_current = df_time[df_time['WKDY'] == w].iloc[0]\n",
    "        if (df_current['SALE_BGN_TM'] != df_first_day['SALE_BGN_TM'] or\n",
    "            df_current['SALE_END_TM'] != df_first_day['SALE_END_TM'] or\n",
    "            df_current['STORE_REST_BGN_TM'] != df_first_day['STORE_REST_BGN_TM'] or\n",
    "            df_current['STORE_REST_END_TM'] != df_first_day['STORE_REST_END_TM']):\n",
    "            same_time = False\n",
    "            break\n",
    "    \n",
    "    # 동일하다면 매일(0)로 통합\n",
    "    if same_time:\n",
    "        # 매일(0)에 해당하는 행 추가\n",
    "        daily_row = df_first_day.copy()\n",
    "        daily_row['WKDY'] = '매일'\n",
    "        \n",
    "        # 기존 요일 행들 제거 후 매일 행만 남김\n",
    "        df_time = df_time[~df_time['WKDY'].isin(weekday_list)]\n",
    "        df_time = pd.concat([df_time, daily_row.to_frame().T], ignore_index=True)\n",
    "df_time.drop(columns=['STORE_NO'], inplace=True)\n",
    "\n",
    "print(df_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                영업시간 브레이크타임\n",
      "0  매일 07시부터 23시59분까지     없음\n"
     ]
    }
   ],
   "source": [
    "# \"영업시간\" 컬럼 생성\n",
    "df_time['영업시간'] = df_time['WKDY'] + \" \" + df_time['SALE_BGN_TM'] + \"부터 \" + df_time['SALE_END_TM'] + \"까지\"\n",
    "\n",
    "# \"브레이크타임\" 컬럼 생성\n",
    "def make_breaktime(row):\n",
    "    start = row['STORE_REST_BGN_TM']\n",
    "    end = row['STORE_REST_END_TM']\n",
    "    if start == \"없음\" or start == \"브레이크타임 없음\" or end == \"없음\" or end == \"브레이크타임 없음\":\n",
    "        return \"없음\"\n",
    "    else:\n",
    "        return start + \"부터 \" + end + \"까지\"\n",
    "\n",
    "df_time['브레이크타임'] = df_time.apply(make_breaktime, axis=1)\n",
    "\n",
    "# 필요없는 열들 정리(선택사항)\n",
    "df_time = df_time[['영업시간', '브레이크타임']]\n",
    "\n",
    "print(df_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  contents\n",
      "0  \"영업시간\": 매일 07시부터 23시59분까지, \"브레이크타임\": 없음\n"
     ]
    }
   ],
   "source": [
    "############### 한 컬럼으로 통합 ###############\n",
    "def create_contents_rowwise(df):\n",
    "    contents_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        row_content = \", \".join([f'\"{col}\": {row[col]}' for col in df.columns])  # 각 행의 컬럼명:값을 \", \"로 결합하여 하나의 문자열 생성\n",
    "        contents_data.append(row_content)\n",
    "    \n",
    "    new_df = pd.DataFrame({'contents': contents_data})  # contents 열을 포함하는 새로운 데이터프레임 생성\n",
    "    return new_df\n",
    "\n",
    "# 함수 호출\n",
    "result_df_time = create_contents_rowwise(df_time)\n",
    "print(result_df_time[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 휴무일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_use = ['STORE_NO', 'HOLIDAY_TYPE_CD']\n",
    "# df_holiday = pd.read_excel(f'/home/user09/beaver/data/shared_files/dataset/dataset_v{CFG.version}.xlsx', sheet_name='HOLIDAY_INFO', usecols=columns_to_use)\n",
    "# df_holiday = df_holiday[df_holiday['STORE_NO']==CFG.store_num]   # 해당 매장 정보만 가져옴\n",
    "# df_holiday.fillna(CFG.fill_nan, inplace=True)\n",
    "# df_holiday.drop(columns=['STORE_NO'], inplace=True)\n",
    "# df_holiday_col = df_holiday.columns\n",
    "# print(df_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############## 컬럼명 변경 ##############\n",
    "# day_column_mapping = {\n",
    "#     # 'PROD_NO': '상품 번호',\n",
    "#     'HOLIDAY_TYPE_CD': '휴무일',\n",
    "# }\n",
    "\n",
    "# for col in df_holiday_col:\n",
    "#     df_holiday = df_holiday.rename(columns={col: day_column_mapping[col]})\n",
    "    \n",
    "# print(df_holiday[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############### 한 컬럼으로 통합 ###############\n",
    "# def create_contents_rowwise(df):\n",
    "#     contents_data = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         row_content = \", \".join([f\"'{col}': {row[col]}\" for col in df.columns])  # 각 행의 컬럼명:값을 \", \"로 결합하여 하나의 문자열 생성\n",
    "#         contents_data.append(row_content)\n",
    "    \n",
    "#     new_df = pd.DataFrame({'contents': contents_data})  # contents 열을 포함하는 새로운 데이터프레임 생성\n",
    "#     return new_df\n",
    "\n",
    "# # 함수 호출\n",
    "# result_df_holiday = create_contents_rowwise(df_holiday)\n",
    "# print(result_df_holiday[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4개 통합 & 피클파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([result_df_store, result_df_pay, result_df_menu, result_df_time], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             contents\n",
      "0                                    \"매장명\": 우아하계 완정역점\n",
      "1                              \"위치\": 인천 서구 완정로10번길 16\n",
      "2                                 \"전화번호\": 01099923537\n",
      "3                                   \"매장 내 테이블 개수\": 18\n",
      "4                                      \"수용 가능 인원\": 72\n",
      "5      '결제수단': 신용카드, 현금, 모바일상품권, 포인트, 매장쿠폰, 선불권, 간편결제\n",
      "6   '간편결제수단': 네이버페이, 비플제로페이, 삼성페이, 알리페이, 앱결제, 앱카드,...\n",
      "7      \"메뉴명\": 우아하계 한판세트, \"가격\": 55000원, \"특징\": ['메인메뉴']\n",
      "8     \"메뉴명\": 숯불닭갈비갈비양념 , \"가격\": 14000원, \"특징\": ['메인메뉴']\n",
      "9     \"메뉴명\": 숯불닭갈비소금구이 , \"가격\": 14000원, \"특징\": ['메인메뉴']\n",
      "10        \"메뉴명\": 닭목살구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "11      \"메뉴명\": 닭목살구이양념 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "12       \"메뉴명\": 닭안창살구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "13     \"메뉴명\": 닭안창살구이양념 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "14      \"메뉴명\": 닭염통양념구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "15       \"메뉴명\": 무뼈닭발구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "16        \"메뉴명\": 한판세트 B, \"가격\": 39000원, \"특징\": ['메인메뉴']\n",
      "17  \"메뉴명\": 능이닭개장, \"가격\": 9000원, \"특징\": ['사이드메뉴', '점심...\n",
      "18  \"메뉴명\": 쑥갓된장, \"가격\": 8000원, \"특징\": ['사이드메뉴', '점심 ...\n",
      "19  \"메뉴명\": 잔치닭국수, \"가격\": 6000원, \"특징\": ['사이드메뉴', '점심...\n",
      "20  \"메뉴명\": 비빔닭국수, \"가격\": 6000원, \"특징\": ['사이드메뉴', '점심...\n",
      "21           \"메뉴명\": 주먹밥, \"가격\": 3000원, \"특징\": ['사이드메뉴']\n",
      "22           \"메뉴명\": 공기밥, \"가격\": 1000원, \"특징\": ['사이드메뉴']\n",
      "23         \"메뉴명\": 또띠아추가, \"가격\": 2000원, \"특징\": ['사이드메뉴']\n",
      "24        \"메뉴명\": 꽈리고추추가, \"가격\": 2000원, \"특징\": ['사이드메뉴']\n",
      "25         \"메뉴명\": 떡사리추가, \"가격\": 2000원, \"특징\": ['사이드메뉴']\n",
      "26             \"메뉴명\": 제로콜라, \"가격\": 2000원, \"특징\": ['음료']\n",
      "27             \"메뉴명\": 환타파인, \"가격\": 2000원, \"특징\": ['음료']\n",
      "28            \"메뉴명\": 스프라이트, \"가격\": 2000원, \"특징\": ['음료']\n",
      "29             \"메뉴명\": 코카콜라, \"가격\": 2000원, \"특징\": ['음료']\n",
      "30    \"메뉴명\": 닭갈비 능이닭개장, \"가격\": 13000원, \"특징\": ['점심 특선']\n",
      "31     \"메뉴명\": 닭갈비 쑥갓된장, \"가격\": 12000원, \"특징\": ['점심 특선']\n",
      "32    \"메뉴명\": 닭갈비 비빔닭국수, \"가격\": 12000원, \"특징\": ['점심 특선']\n",
      "33    \"메뉴명\": 닭갈비 잔치닭국수, \"가격\": 12000원, \"특징\": ['점심 특선']\n",
      "34          \"메뉴명\": 참이슬 후레쉬, \"가격\": 5000원, \"특징\": ['주류']\n",
      "35               \"메뉴명\": 세로, \"가격\": 5000원, \"특징\": ['주류']\n",
      "36            \"메뉴명\": 진로이즈백, \"가격\": 5000원, \"특징\": ['주류']\n",
      "37               \"메뉴명\": 켈리, \"가격\": 5000원, \"특징\": ['주류']\n",
      "38               \"메뉴명\": 테라, \"가격\": 5000원, \"특징\": ['주류']\n",
      "39               \"메뉴명\": 카스, \"가격\": 5000원, \"특징\": ['주류']\n",
      "40             \"메뉴명\": 처음처럼, \"가격\": 5000원, \"특징\": ['주류']\n",
      "41         \"메뉴명\": 참이슬 오리지널, \"가격\": 5000원, \"특징\": ['주류']\n",
      "42             \"메뉴명\": 별빛청하, \"가격\": 6000원, \"특징\": ['주류']\n",
      "43            \"메뉴명\": 장수막걸리, \"가격\": 4000원, \"특징\": ['주류']\n",
      "44               \"메뉴명\": 청하, \"가격\": 6000원, \"특징\": ['주류']\n",
      "45            \"영업시간\": 매일 07시부터 23시59분까지, \"브레이크타임\": 없음\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 정보 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \":\"를 기준으로 분리하여 앞의 키워드를 추출한 후, 존재 여부 확인\n",
    "# existing_info = [content.split(\":\")[0].strip() for content in df[\"contents\"]]\n",
    "# missing_info = [info for info in CFG.basic_info if info not in existing_info]\n",
    "# for info in missing_info:\n",
    "#     df = pd.concat([df, pd.DataFrame({\"contents\": [f\"{info}: 정보없음\"]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             contents\n",
      "0                                    \"매장명\": 우아하계 완정역점\n",
      "1                              \"위치\": 인천 서구 완정로10번길 16\n",
      "2                                 \"전화번호\": 01099923537\n",
      "3                                   \"매장 내 테이블 개수\": 18\n",
      "4                                      \"수용 가능 인원\": 72\n",
      "5      '결제수단': 신용카드, 현금, 모바일상품권, 포인트, 매장쿠폰, 선불권, 간편결제\n",
      "6   '간편결제수단': 네이버페이, 비플제로페이, 삼성페이, 알리페이, 앱결제, 앱카드,...\n",
      "7      \"메뉴명\": 우아하계 한판세트, \"가격\": 55000원, \"특징\": ['메인메뉴']\n",
      "8     \"메뉴명\": 숯불닭갈비갈비양념 , \"가격\": 14000원, \"특징\": ['메인메뉴']\n",
      "9     \"메뉴명\": 숯불닭갈비소금구이 , \"가격\": 14000원, \"특징\": ['메인메뉴']\n",
      "10        \"메뉴명\": 닭목살구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "11      \"메뉴명\": 닭목살구이양념 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "12       \"메뉴명\": 닭안창살구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "13     \"메뉴명\": 닭안창살구이양념 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "14      \"메뉴명\": 닭염통양념구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "15       \"메뉴명\": 무뼈닭발구이 , \"가격\": 13000원, \"특징\": ['메인메뉴']\n",
      "16        \"메뉴명\": 한판세트 B, \"가격\": 39000원, \"특징\": ['메인메뉴']\n",
      "17  \"메뉴명\": 능이닭개장, \"가격\": 9000원, \"특징\": ['사이드메뉴', '점심...\n",
      "18  \"메뉴명\": 쑥갓된장, \"가격\": 8000원, \"특징\": ['사이드메뉴', '점심 ...\n",
      "19  \"메뉴명\": 잔치닭국수, \"가격\": 6000원, \"특징\": ['사이드메뉴', '점심...\n",
      "20  \"메뉴명\": 비빔닭국수, \"가격\": 6000원, \"특징\": ['사이드메뉴', '점심...\n",
      "21           \"메뉴명\": 주먹밥, \"가격\": 3000원, \"특징\": ['사이드메뉴']\n",
      "22           \"메뉴명\": 공기밥, \"가격\": 1000원, \"특징\": ['사이드메뉴']\n",
      "23         \"메뉴명\": 또띠아추가, \"가격\": 2000원, \"특징\": ['사이드메뉴']\n",
      "24        \"메뉴명\": 꽈리고추추가, \"가격\": 2000원, \"특징\": ['사이드메뉴']\n",
      "25         \"메뉴명\": 떡사리추가, \"가격\": 2000원, \"특징\": ['사이드메뉴']\n",
      "26             \"메뉴명\": 제로콜라, \"가격\": 2000원, \"특징\": ['음료']\n",
      "27             \"메뉴명\": 환타파인, \"가격\": 2000원, \"특징\": ['음료']\n",
      "28            \"메뉴명\": 스프라이트, \"가격\": 2000원, \"특징\": ['음료']\n",
      "29             \"메뉴명\": 코카콜라, \"가격\": 2000원, \"특징\": ['음료']\n",
      "30    \"메뉴명\": 닭갈비 능이닭개장, \"가격\": 13000원, \"특징\": ['점심 특선']\n",
      "31     \"메뉴명\": 닭갈비 쑥갓된장, \"가격\": 12000원, \"특징\": ['점심 특선']\n",
      "32    \"메뉴명\": 닭갈비 비빔닭국수, \"가격\": 12000원, \"특징\": ['점심 특선']\n",
      "33    \"메뉴명\": 닭갈비 잔치닭국수, \"가격\": 12000원, \"특징\": ['점심 특선']\n",
      "34          \"메뉴명\": 참이슬 후레쉬, \"가격\": 5000원, \"특징\": ['주류']\n",
      "35               \"메뉴명\": 세로, \"가격\": 5000원, \"특징\": ['주류']\n",
      "36            \"메뉴명\": 진로이즈백, \"가격\": 5000원, \"특징\": ['주류']\n",
      "37               \"메뉴명\": 켈리, \"가격\": 5000원, \"특징\": ['주류']\n",
      "38               \"메뉴명\": 테라, \"가격\": 5000원, \"특징\": ['주류']\n",
      "39               \"메뉴명\": 카스, \"가격\": 5000원, \"특징\": ['주류']\n",
      "40             \"메뉴명\": 처음처럼, \"가격\": 5000원, \"특징\": ['주류']\n",
      "41         \"메뉴명\": 참이슬 오리지널, \"가격\": 5000원, \"특징\": ['주류']\n",
      "42             \"메뉴명\": 별빛청하, \"가격\": 6000원, \"특징\": ['주류']\n",
      "43            \"메뉴명\": 장수막걸리, \"가격\": 4000원, \"특징\": ['주류']\n",
      "44               \"메뉴명\": 청하, \"가격\": 6000원, \"특징\": ['주류']\n",
      "45            \"영업시간\": 매일 07시부터 23시59분까지, \"브레이크타임\": 없음\n"
     ]
    }
   ],
   "source": [
    "# 결과 저장 및 출력\n",
    "df.to_excel(CFG.save_path, index=False)   # 전처리한 엑셀 파일 저장\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 엑셀파일 DB화(pickle파일로 변환) ##### Extracting information from the \"Details\" column to create documents\n",
    "docs = []\n",
    "for _, row in df.iterrows():\n",
    "    details = row['contents']\n",
    "    # metadata = {}\n",
    "    \n",
    "    # # Parse key-value pairs in the \"Details\" column\n",
    "    # for detail in details.split('\\n'):\n",
    "    #     if ':' in detail:\n",
    "    #         key, value = detail.split(':', 1)\n",
    "            # metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    docs.append(Document(page_content=details))#, metadata=metadata))\n",
    "\n",
    "# Embeddings and vector store setup\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=CFG.embedding_model,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "db = FAISS.from_documents(docs, hf)\n",
    "\n",
    "# Save the FAISS vector store and documents as pickle\n",
    "db.save_local(f\"{CFG.output_path}/{CFG.store_num}_faiss{CFG.version}\")\n",
    "\n",
    "with open(f\"{CFG.output_path}/{CFG.store_num}_docs{CFG.version}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)\n",
    "\n",
    "# Load the FAISS vector store\n",
    "db = FAISS.load_local(f\"/home/user09/beaver/data/db/{CFG.store_num}_faiss{CFG.version}\", hf, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Create retrievers\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": CFG.retriever_k})\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = CFG.retriever_k\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever, bm25_retriever],\n",
    "    weights=[CFG.retriever_bert_weight, 1 - CFG.retriever_bert_weight]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beaver3.10",
   "language": "python",
   "name": "beaver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
