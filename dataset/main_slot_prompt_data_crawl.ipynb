{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # store=\"프랭크버거\"\n",
    "    output_path = \"/home/user09/beaver/data/db\"\n",
    "    save_path = \"\"\n",
    "    embedding_model=\"BAAI/bge-m3\"\n",
    "    retriever_k=5\n",
    "    retriever_bert_weight=0.7\n",
    "    version='11'\n",
    "    seed=42\n",
    "    \n",
    "# CFG.save_path = CFG.output_path + CFG.store + \"_temp.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = \"홍콩반점\"\n",
    "\n",
    "df = pd.read_excel(f'/home/user09/beaver/data/shared_files/dataset/dataset_v{CFG.version}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user09/venv/beaver/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Extracting information from the \"Details\" column to create documents\n",
    "docs = []\n",
    "for _, row in df.iterrows():\n",
    "    details = row['Details']\n",
    "    # metadata = {}\n",
    "    \n",
    "    # # Parse key-value pairs in the \"Details\" column\n",
    "    # for detail in details.split('\\n'):\n",
    "    #     if ':' in detail:\n",
    "    #         key, value = detail.split(':', 1)\n",
    "            # metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    docs.append(Document(page_content=details))#, metadata=metadata))\n",
    "\n",
    "# Embeddings and vector store setup\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=CFG.embedding_model,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "db = FAISS.from_documents(docs, hf)\n",
    "\n",
    "# Save the FAISS vector store and documents as pickle\n",
    "db.save_local(f\"{CFG.output_path}/{store}_faiss{CFG.version}\")\n",
    "\n",
    "with open(f\"{CFG.output_path}/{store}_docs{CFG.version}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)\n",
    "\n",
    "# Load the FAISS vector store\n",
    "db = FAISS.load_local(f\"/home/user09/beaver/data/db/{store}_faiss{CFG.version}\", hf, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Create retrievers\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": CFG.retriever_k})\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = CFG.retriever_k\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever, bm25_retriever],\n",
    "    weights=[CFG.retriever_bert_weight, 1 - CFG.retriever_bert_weight]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Content: 영업 시간: 11:30 - 21:3020:30 라스트오더\n",
      "Metadata: {}\n",
      "\n",
      "Document 2:\n",
      "Content: 매장 전화번호: 02-555-8883\n",
      "Metadata: {}\n",
      "\n",
      "Document 3:\n",
      "Content: 매장 위치: 서울 강남구 테헤란로4길 27 2층\n",
      "Metadata: {}\n",
      "\n",
      "Document 4:\n",
      "Content: 운영 요일: 매일\n",
      "Metadata: {}\n",
      "\n",
      "Document 5:\n",
      "Content: 메뉴명: 쟁반짜장(2인), 메뉴 설명: 불 맛 가득! 채소와 고기 그리고 해산물을 푸짐하게 담았습니다., 가격: 16,000원\n",
      "Metadata: {}\n",
      "\n",
      "Document 6:\n",
      "Content: 메뉴명: 짜장소스 1통 (350g), 메뉴 설명: 홍콩반점 수제 짜장 소스! 3통 구매시 8500원! 집에서도 간편하게 즐겨요, 가격: 3,500원\n",
      "Metadata: {}\n",
      "\n",
      "Document 7:\n",
      "Content: 메뉴명: 단팥춘권(10개), 메뉴 설명: 달콤한 팥앙금이 가득! 후식으로 깔끔하게 마무리, 가격: 3,000원\n",
      "Metadata: {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3609942/3339529135.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = ensemble_retriever.get_relevant_documents(input_query)\n"
     ]
    }
   ],
   "source": [
    "# Example input and retrieving relevant documents\n",
    "input_query = \"영업시간이 어떻게 돼\"\n",
    "retrieved_docs = ensemble_retriever.get_relevant_documents(input_query)\n",
    "\n",
    "# Print out the retrieved documents\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"Document {i}:\\nContent: {doc.page_content}\\nMetadata: {doc.metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메타데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting information from the \"Details\" column to create documents\n",
    "docs = []\n",
    "for _, row in df.iterrows():\n",
    "    details = row['Details']\n",
    "    metadata = {}\n",
    "    \n",
    "    # Parse key-value pairs in the \"Details\" column\n",
    "    for detail in details.split('\\n'):\n",
    "        if ':' in detail:\n",
    "            key, value = detail.split(':', 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    docs.append(Document(page_content=details, metadata=metadata))\n",
    "\n",
    "# Embeddings and vector store setup\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=CFG.embedding_model,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "db = FAISS.from_documents(docs, hf)\n",
    "\n",
    "# Save the FAISS vector store and documents as pickle\n",
    "db.save_local(f\"{CFG.output_path}/{store}_faiss{CFG.version}\")\n",
    "\n",
    "with open(f\"{CFG.output_path}/{store}_docs{CFG.version}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)\n",
    "\n",
    "# Load the FAISS vector store\n",
    "db = FAISS.load_local(f\"/mnt/data/{store}_faiss{CFG.version}\", hf, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Create retrievers\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": CFG.retriever_k})\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = CFG.retriever_k\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever, bm25_retriever],\n",
    "    weights=[CFG.retriever_bert_weight, 1 - CFG.retriever_bert_weight]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Content: 전화번호: 02-555-8883\n",
      "Metadata: {'전화번호': '02-555-8883'}\n",
      "\n",
      "Document 2:\n",
      "Content: 주소: 서울 강남구 테헤란로4길 27 2층\n",
      "Metadata: {'주소': '서울 강남구 테헤란로4길 27 2층'}\n",
      "\n",
      "Document 3:\n",
      "Content: 오시는길: 강남역 3번 출구에서 16m미터\n",
      "Metadata: {'오시는길': '강남역 3번 출구에서 16m미터'}\n",
      "\n",
      "Document 4:\n",
      "Content: 영업시간: 매일11:30 - 21:3020:30 라스트오더\n",
      "Metadata: {'영업시간': '매일11:30 - 21:3020:30 라스트오더'}\n",
      "\n",
      "Document 5:\n",
      "Content: 메뉴명: 쟁반짜장(2인), 메뉴특징: 불 맛 가득! 채소와 고기 그리고 해산물을 푸짐하게 담았습니다., 가격: 16,000원\n",
      "Metadata: {'메뉴명': '쟁반짜장(2인), 메뉴특징: 불 맛 가득! 채소와 고기 그리고 해산물을 푸짐하게 담았습니다., 가격: 16,000원'}\n",
      "\n",
      "Document 6:\n",
      "Content: 메뉴명: 멘보샤(5개), 메뉴특징: 겉바속탱! 탱글탱글한 새우살이 가득! 매콤달콤한 칠리소스와 환상의 짝꿍입니다, 가격: 9,900원\n",
      "Metadata: {'메뉴명': '멘보샤(5개), 메뉴특징: 겉바속탱! 탱글탱글한 새우살이 가득! 매콤달콤한 칠리소스와 환상의 짝꿍입니다, 가격: 9,900원'}\n",
      "\n",
      "Document 7:\n",
      "Content: 메뉴명: 고추짬뽕, 메뉴특징: 내가 찾던 매운맛! 싱싱한 청양고추로 깔끔한 매운맛을 더합니다., 가격: 8,900원\n",
      "Metadata: {'메뉴명': '고추짬뽕, 메뉴특징: 내가 찾던 매운맛! 싱싱한 청양고추로 깔끔한 매운맛을 더합니다., 가격: 8,900원'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example input and retrieving relevant documents\n",
    "input_query = \"영업시간이 어떻게 돼\"\n",
    "retrieved_docs = ensemble_retriever.get_relevant_documents(input_query)\n",
    "\n",
    "# Print out the retrieved documents\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"Document {i}:\\nContent: {doc.page_content}\\nMetadata: {doc.metadata}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beaver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
